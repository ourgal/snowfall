From d1b711f5400406679f500f96576291108f0cb834 Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Sat, 15 Mar 2025 22:31:15 +0100
Subject: [PATCH 64/67] CACHYOS: bbr3-6.14: resync with latest changes

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>

Link: https://github.com/CachyOS/linux/commit/889e21b87e8f07ae0caf20d938e154200a5d44f9
---
 include/linux/tcp.h   | 10 +++++-----
 net/ipv4/bpf_tcp_ca.c |  5 -----
 net/ipv4/tcp_bbr.c    |  6 ++++--
 3 files changed, 9 insertions(+), 12 deletions(-)

diff --git a/include/linux/tcp.h b/include/linux/tcp.h
index f4f7b9373f38..811850c240cc 100644
--- a/include/linux/tcp.h
+++ b/include/linux/tcp.h
@@ -248,7 +248,8 @@ struct tcp_sock {
 	void (*tcp_clean_acked)(struct sock *sk, u32 acked_seq);
 #endif
 	u32	snd_ssthresh;	/* Slow start size threshold		*/
-	u8	recvmsg_inq : 1;/* Indicate # of bytes in queue upon recvmsg */
+	u32	recvmsg_inq : 1,/* Indicate # of bytes in queue upon recvmsg */
+		fast_ack_mode:1;/* ack ASAP if >1 rcv_mss received? */
 	__cacheline_group_end(tcp_sock_read_rx);

 	/* TX read-write hotpath cache lines */
@@ -305,7 +306,8 @@ struct tcp_sock {
  */
 	struct tcp_options_received rx_opt;
 	u8	nonagle     : 4,/* Disable Nagle algorithm?             */
-		rate_app_limited:1;  /* rate_{delivered,interval_us} limited? */
+		rate_app_limited:1,  /* rate_{delivered,interval_us} limited? */
+		tlp_orig_data_app_limited:1; /* app-limited before TLP rtx? */
 	__cacheline_group_end(tcp_sock_write_txrx);

 	/* RX read-write hotpath cache lines */
@@ -373,9 +375,7 @@ struct tcp_sock {
 	u8	compressed_ack;
 	u8	dup_ack_counter:2,
 		tlp_retrans:1,	/* TLP is a retransmission */
-		fast_ack_mode:2, /* which fast ack mode ? */
-		tlp_orig_data_app_limited:1, /* app-limited before TLP rtx? */
-		unused:2;
+		unused:5;
 	u8	thin_lto    : 1,/* Use linear timeouts for thin streams */
 		fastopen_connect:1, /* FASTOPEN_CONNECT sockopt */
 		fastopen_no_cookie:1, /* Allow send/recv SYN+data without a cookie */
diff --git a/net/ipv4/bpf_tcp_ca.c b/net/ipv4/bpf_tcp_ca.c
index 3f38b34fa803..27893b774e08 100644
--- a/net/ipv4/bpf_tcp_ca.c
+++ b/net/ipv4/bpf_tcp_ca.c
@@ -285,10 +285,6 @@ static u32 bpf_tcp_ca_tso_segs(struct sock *sk, unsigned int mss_now)
 	return 0;
 }

-static void bpf_tcp_ca_skb_marked_lost(struct sock *sk, const struct sk_buff *skb)
-{
-}
-
 static void bpf_tcp_ca_cong_control(struct sock *sk, u32 ack, int flag,
 				    const struct rate_sample *rs)
 {
@@ -320,7 +316,6 @@ static struct tcp_congestion_ops __bpf_ops_tcp_congestion_ops = {
 	.in_ack_event = bpf_tcp_ca_in_ack_event,
 	.pkts_acked = bpf_tcp_ca_pkts_acked,
 	.tso_segs = bpf_tcp_ca_tso_segs,
-	.skb_marked_lost = bpf_tcp_ca_skb_marked_lost,
 	.cong_control = bpf_tcp_ca_cong_control,
 	.undo_cwnd = bpf_tcp_ca_undo_cwnd,
 	.sndbuf_expand = bpf_tcp_ca_sndbuf_expand,
diff --git a/net/ipv4/tcp_bbr.c b/net/ipv4/tcp_bbr.c
index cc3bade71088..099d5862a585 100644
--- a/net/ipv4/tcp_bbr.c
+++ b/net/ipv4/tcp_bbr.c
@@ -457,7 +457,8 @@ static void bbr_init_pacing_rate_from_rtt(struct sock *sk)
 	bw = (u64)tcp_snd_cwnd(tp) * BW_UNIT;
 	do_div(bw, rtt_us);
 	WRITE_ONCE(sk->sk_pacing_rate,
-		   bbr_bw_to_pacing_rate(sk, bw, bbr_param(sk, startup_pacing_gain)));
+		   bbr_bw_to_pacing_rate(sk, bw,
+					 bbr_param(sk, startup_pacing_gain)));
 }

 /* Pace using current bw estimate and a gain factor. */
@@ -2034,7 +2035,8 @@ static bool bbr_run_fast_path(struct sock *sk, bool *update_model,
 	return false;
 }

-__bpf_kfunc static void bbr_main(struct sock *sk, u32 ack, int flag, const struct rate_sample *rs)
+__bpf_kfunc static void bbr_main(struct sock *sk, u32 ack, int flag,
+				 const struct rate_sample *rs)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
--
2.50.1
